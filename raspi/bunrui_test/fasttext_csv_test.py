import fasttext
import pandas as pd
import os
import chromadb
from sentence_transformers import SentenceTransformer as ST
from dotenv import load_dotenv
from gtts import gTTS
import PyPDF2
import uuid
from google import genai as gemini
from google.genai import types
import requests

# Teams Webhook URL å‹•ã„ã¦ã„ã‚‹ã¿ãŸã„ã ã‹ã‚‰.envã‹ã‚‰ã‚¦ã‚§ãƒ–ãƒ•ãƒƒã‚¯URLã‚’å–å¾—ã§ãã‚‹ã‚ˆã†ã«ã—ã¦å®Ÿè£…ã™ã‚‹ã®ã¯ã‚ã‚Š
#TEAMS_WEBHOOK_URL = "https://utokai.webhook.office.com/webhookb2/442834dd-3d07-4e81-8059-b4352e75bd0c@8283096f-bcce-44d0-8f54-e57aa84d1a22/IncomingWebhook/03c1777ddb7542ccb1161190bfc1581a/aad18c1b-d1c6-46b2-adcc-3c163218c4d5/V2EqcJ0hRlkvsr1ECTerA_IHrpZ5crAXa1CVZGeJ7RKto1"

#def send_conversation_to_teams(user_input, log_label, score, log_response):
#    log_text = (
#        f"**ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›:** {user_input}\n"
#        f"**åˆ¤å®šãƒ©ãƒ™ãƒ«:** {log_label} (score={score:.2f})\n"
#        f"**AIå¿œç­”:** {log_response}"
#    )

#    payload = {
#        "text": log_text  # Teamsã¯"text"ã‚­ãƒ¼ã§é€ã‚‹
#    }

#    requests.post(TEAMS_WEBHOOK_URL, json=payload)

# ====== Gemini è¨­å®š ======
load_dotenv()
GEMINI_TOKEN = os.getenv("GEMINI_TOKEN")

gemini_client = gemini.Client(api_key=GEMINI_TOKEN)
gemini_model = "gemini-2.5-flash-lite"
gemini_config = types.GenerateContentConfig(temperature=0.7,max_output_tokens=512)

# ====== SentenceTransformer & Chroma è¨­å®š ======
embedder = ST("all-MiniLM-L6-v2")

chroma_client = chromadb.Client()

# ====== æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã‚Œã°å‰Šé™¤ï¼ˆé‡è¤‡ç™»éŒ²é˜²æ­¢ï¼‰ ======
try:
    chroma_client.delete_collection("school_test.pdf")
except:
    pass

# ====== æ–°è¦ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ ======
collection = chroma_client.get_or_create_collection("school_test.pdf")

# ====== PDF ã‚’ Chroma ã«ç™»éŒ² ======

def load_pdf_into_chroma(pdf_path):
    print("ğŸ“˜ PDF ã‹ã‚‰ Chroma ã¸ãƒ‡ãƒ¼ã‚¿ç™»éŒ²ä¸­...")

    # PDF èª­ã¿è¾¼ã¿
    with open(pdf_path, "rb") as f:
        reader = PyPDF2.PdfReader(f)
        texts = []
        for page in reader.pages:
            text = page.extract_text()
            if text:
                texts.append(text.strip())

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ï¼ˆ500æ–‡å­—ã”ã¨ï¼‰
    chunks = []
    for text in texts:
        while len(text) > 500:
            chunks.append(text[:500])
            text = text[500:]
        if text:
            chunks.append(text)

    # Chroma ã«è¿½åŠ 
    for chunk in chunks:
        emb = embedder.encode(chunk).tolist()
        collection.add(
            ids=[str(uuid.uuid4())],
            documents=[chunk],
            embeddings=[emb]
        )

    print(f"ğŸ“š ç™»éŒ²å®Œäº†ï¼ {len(chunks)} ãƒãƒ£ãƒ³ã‚¯è¿½åŠ ã—ã¾ã—ãŸ")

# ====== PDF èª­ã¿è¾¼ã¿å®Ÿè¡Œ ======
load_pdf_into_chroma("school_test.pdf")

print("ğŸ“¦ Chroma ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ–‡æ›¸æ•°ï¼š", collection.count())
print("âœ… Gemini API ã¨ Chroma åˆæœŸåŒ–å®Œäº†")


def gemini_answer_from_pdf(question):
    query_vec = embedder.encode(question).tolist()
    results = collection.query(query_embeddings=[query_vec], n_results=3)
    context = "\n".join(results["documents"][0])
    print(context)

    prompt = f"""
ã‚ãªãŸã¯ã€Œæ±æµ·å¤§å­¦ã€ã®æ•™å¸«ã§ã™ã€‚
ä»¥ä¸‹ã®å­¦æ ¡æƒ…å ±ã«åŸºã¥ã„ã¦ã€å…ˆã»ã©èª­ã¿è¾¼ã‚“ã PDFã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚
æƒ…å ±ãŒãªã„å ´åˆã¯ã€Œã™ã„ã¾ã›ã‚“ã€ãã®è³ªå•ã«ã¯ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚ã€ã¨ã ã‘è¿”ã—ã¦ãã ã•ã„ã€‚ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãªã©ã¯ã—ãªãã¦ã„ã„ã§ã™ã—ã€å‰ç½®ãã‚‚ã„ã‚Šã¾ã›ã‚“ã€‚
ã‚‚ã—ã€ç­”ãˆã‚Œã‚‹å†…å®¹ãŒã‚ã‚‹å ´åˆã€å˜èªã§ç­”ãˆãšä¸»èªã¨è¿°èªã¯ã„ã‚Œã¦ç­”ãˆã¦ãã ã•ã„ã€‚

ã€å­¦æ ¡æƒ…å ±ã€‘
{context}

ã€è³ªå•ã€‘
{question}
"""

    try:
        response = client.chat.completions.create(
            model="gemini-2.5-flash",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ•™è‚²è€…ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=512,
        )

        # âœ… content ãŒ None ã®å ´åˆã«å‚™ãˆã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’è¿½åŠ 
        answer = None
        if hasattr(response.choices[0].message, "content") and response.choices[0].message.content:
            answer = response.choices[0].message.content.strip()
        elif hasattr(response, "output_text") and response.output_text:
            answer = response.output_text.strip()
        else:
            answer = "ã™ã¿ã¾ã›ã‚“ã€å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

    except Exception as e:
        answer = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

    # ===== éŸ³å£°å‡ºåŠ› =====
    print(f"\n=== Geminiã®å›ç­” ===\n{answer}")
    tts = gTTS(text=answer, lang='ja')
    tts.save("answer.mp3")
    os.system("start answer.mp3")

    return answer




# ===== CSVã‹ã‚‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ =====
df = pd.read_csv("C:/Users/naoma/Downloads/senior_thesis/bunrui_test/gakusyudata.csv")  # ãƒ•ã‚¡ã‚¤ãƒ«åã«æ³¨æ„

# ===== ä¸€æ™‚çš„ãª fastText å½¢å¼ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ï¼ˆ__label__ä»˜ãï¼‰ =====
with open("train.txt", "w", encoding="utf-8") as f:
    for _, row in df.iterrows():
        label = row["label"]
        text = row["text"]
        f.write(f"__label__{label} {text}\n")

# ===== ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ =====
model = fasttext.train_supervised(
    input="train.txt",
    epoch=800,      # å¤šã™ãã‚‹ã¨éå­¦ç¿’ã™ã‚‹ã“ã¨ã‚‚
    lr=1,         # å­¦ç¿’ç‡ã¯1.5â†’0.5ãã‚‰ã„ãŒå®‰å®š
    wordNgrams=2,    # 2-gramæ¨å¥¨
    minn=2,           # æ–‡å­—n-gramæœ€å°
    maxn=5,           # æ–‡å­—n-gramæœ€å¤§ï¼ˆæ—¥æœ¬èªã«ã¯åŠ¹æœçš„ï¼‰
    verbose=2
)

# ===== å¿œç­”ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆãƒ©ãƒ™ãƒ«ã”ã¨ï¼‰ =====
template_responses = {
    "æ¬ å¸­": "æ¬ å¸­ã§ã™ã­ã€‚ã‹ã—ã“ã¾ã‚Šã¾ã—ãŸã€‚",
    "é…åˆ»": "é…åˆ»ã§ã™ã­ã€‚æ°—ã‚’ã¤ã‘ã¦ãŠè¶Šã—ãã ã•ã„ã€‚",
}

# ===== æ¨è«–å¯¾è±¡ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼‰ =====
user_input = "ç—…é™¢ã‹ã‚‰ç™»æ ¡ã—ã¾ã™"

# ===== æ¨è«–å‡¦ç† =====
labels, scores = model.predict(user_input)
label = labels[0].replace("__label__", "")
score = scores[0]
print("score:", score)

# ===== æ¨è«–ï¼ˆä¸Šä½2ä»¶ï¼‰ =====
labels, scores = model.predict(user_input, k=2)  # ä¸Šä½2ä»¶ã¾ã§å–å¾—
label1, score1 = labels[0].replace("__label__", ""), scores[0]
label2, score2 = labels[1].replace("__label__", ""), scores[1] # ã‚ˆãè¦‹ãŸã‚‰label2ã£ã¦ã©ã“ã‚‚å‚ç…§ã—ã¦ãªããªã„ï¼Ÿ

# ===== åˆ†å²å‡¦ç† =====
if label1 == "ãã®ä»–":
    print(f"[éå®šå‹å‡¦ç†] â†’ ãƒ©ãƒ™ãƒ«ãŒ 'ãã®ä»–' ã®ãŸã‚ Gemini ã¸ (score={score1:.2f})")
    answer = gemini_answer_from_pdf(user_input)
    print("â†’ Geminiå¿œç­”:", answer)
    # ãƒ­ã‚°ç”¨ãƒ©ãƒ™ãƒ«ã‚’ä¸Šæ›¸ã
    log_label = "ãã®ä»–(Gemini)"
    log_response = answer
    save_conversation_log(user_input, log_label, score1, answer)

elif score1 >= 0.7 and (score1 - score2) >= 0.2:
    response = template_responses.get(label1, "å†…å®¹ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚")
    print(f"[å®šå‹å‡¦ç†] â†’ ãƒ©ãƒ™ãƒ«: {label1} (score={score1:.2f})")
    print("â†’ å¿œç­”:", response)
    
    log_label = label1
    log_response = response
    
    save_conversation_log(user_input, log_label, score1, response)

else:
    print(f"[éå®šå‹å‡¦ç†] â†’ æ›–æ˜§ã¾ãŸã¯æœªçŸ¥ (score={score1:.2f}, æ¬¡ç‚¹ã¨ã®å·®={score1 - score2:.2f})")
    answer = gemini_answer_from_pdf(user_input)
    print("â†’ Geminiå¿œç­”:", answer)
    
    log_label = "æ›–æ˜§(Gemini)"
    log_response = answer
    save_conversation_log(user_input, log_label, score1, answer)
    
    # ===== æœ€çµ‚ç¢ºèªï¼ˆ"ãã®ä»–" ã®å ´åˆã¯è¡Œã‚ãªã„ï¼‰ =====
if log_label not in ["ãã®ä»–(Gemini)", "æ›–æ˜§(Gemini)"]:
    confirm = input(f"\næœ€çµ‚ç¢ºèªã§ã™ã€‚\n\nã‚ãªãŸã®ç”³å‘Šã¯ã€Œ{log_label}ã€ã§é–“é•ã„ã‚ã‚Šã¾ã›ã‚“ã‹ï¼Ÿ\nã€Œã¯ã„ã€ã¾ãŸã¯ã€Œã„ã„ãˆã€ã§ãŠç­”ãˆãã ã•ã„: ")

    if confirm.lower() == "ã¯ã„":
        print("äº†è§£ã—ã¾ã—ãŸã€‚è¨˜éŒ²ã—ã¦ãŠãã¾ã™ã€‚")
    else:
        print("\nå¤±ç¤¼ã—ã¾ã—ãŸã€‚ã§ã¯æ”¹ã‚ã¦æ•™ãˆã¦ãã ã•ã„ã€‚")
        
        # æ¬ å¸­ or é…åˆ» ã®ã©ã¡ã‚‰ã‹ã‚’ç›´æ¥å…¥åŠ›
        while True:
            fixed = input("ã€Œæ¬ å¸­ã€ã‹ã€Œé…åˆ»ã€ã§å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()

            if fixed in ["æ¬ å¸­", "é…åˆ»"]:
                print(f"\nã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ã€Œ{fixed}ã€ã¨ã—ã¦è¨˜éŒ²ã—ã¾ã™ã€‚")
                log_label = fixed               # â† æ­£ã—ã„ãƒ©ãƒ™ãƒ«ã«ä¸Šæ›¸ã
                log_response = template_responses.get(fixed, "å†…å®¹ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚")
                break
            else:
                print("å…¥åŠ›ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚'æ¬ å¸­' ã¾ãŸã¯ 'é…åˆ»' ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

#teamsé€ä¿¡ç”¨
response = template_responses.get(log_label, "å†…å®¹ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚")
#send_conversation_to_teams(user_input, log_label, score1, log_response)

